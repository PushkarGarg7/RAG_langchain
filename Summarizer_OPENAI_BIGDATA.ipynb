{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNf2W+TX0oCkJ4hNGGfy1uc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PushkarGarg7/RAG_langchain/blob/main/Summarizer_OPENAI_BIGDATA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWtUwERyCB0Z",
        "outputId": "8b7565bc-f040-482c-cc2c-773dfc949a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.34.0-py3-none-any.whl (325 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "NxV0Cps7Mffs"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df=pd.read_csv(\"logistics_service_responses 2.csv\")\n",
        "df2=df.head(500000)\n",
        "text_responses=df2[\"Response\"].dropna().tolist()\n",
        "# Define the path to the output text file\n",
        "output_file_path = 'text_responses2.txt'\n",
        "\n",
        "# Write the text responses to the text file\n",
        "with open(output_file_path, 'w') as file:\n",
        "    for response in text_responses:\n",
        "        file.write(response + '\\n')\n",
        "\n",
        "print(f'Text responses have been written to {output_file_path}')\n",
        "with open('text_responses2.txt', 'r') as file:\n",
        "    feedback = file.read()\n",
        "\n",
        "# Eliminate newline tokens\n",
        "feedback = feedback.replace('\\n', ' ')\n",
        "# print(feedback)\n",
        "with open('processed_feedback2.txt', 'w') as file:\n",
        "    file.write(feedback)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFGBSJIkCfVu",
        "outputId": "a90fd57e-1882-4b59-e2d3-7bc6ffddb44f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text responses have been written to text_responses2.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpOxOSJOBlOv"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=\"APIKEY\")   #set environment instead"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-7CYGJqfBrMc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "974b8eda-1fb9-4d31-a9ae-57e0d4067ff3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'DataFrame' object has no attribute 'random'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-63435f521ebe>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5991\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'random'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# my_assistants = client.beta.assistants.list(\n",
        "#     order=\"desc\",\n",
        "#     limit=\"20\",\n",
        "# )\n",
        "# print(my_assistants.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOkFIGqeDM2G",
        "outputId": "db47592a-5c56-42e6-faee-c84fdc659798"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'text_responses3.txt'\n",
        "with open(file_path, 'rb') as f:\n",
        "    file_response = client.files.create(\n",
        "        file=f,\n",
        "        purpose='assistants',\n",
        "    )\n",
        "    print(file_response)\n",
        "\n",
        "file_id = file_response.id"
      ],
      "metadata": {
        "id": "CydqpaFKDHdo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08735954-e510-407c-fdaa-a86304cb6917"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FileObject(id='file-PqYWF09Lqy2qLOpQt7nVO3yw', bytes=33439946, created_at=1718278776, filename='text_responses3.txt', object='file', purpose='assistants', status='processed', status_details=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "    These responses are customer survey responses by customers for a particular survey. The agent has to extract the info from the file as follows:\n",
        "    1. General summary of 5-6 lines, like most users think this that etc.\n",
        "    2. Pain points: What were the most frequent disliked things by users.\n",
        "    3. Suggestions: What can you imporve.\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "6DlKq9NsQ6aU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p73cwxGJRSDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in assistants:\n",
        "  client.beta.assistants.delete(i[\"id\"])\n"
      ],
      "metadata": {
        "id": "keyJeWgcDGzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assistant = client.beta.assistants.create(\n",
        "#   name=\"Sur\",\n",
        "#   instructions=\"You have conducted a survey for your service/product and you have collected survey responses for it, your goal is to analyse those responses and give a conscise summary with key points.\",\n",
        "#   tools=[{\"type\": \"code_interpreter\"}],\n",
        "#   model=\"gpt-3.5-turbo\",\n",
        "#   tool_resources={\n",
        "#     \"code_interpreter\": {\n",
        "#       \"file_ids\": [file.id]\n",
        "#     }\n",
        "#   }\n",
        "# )\n",
        "assistant_response = client.beta.assistants.create(\n",
        "    name=\"Survey Summarizer\",\n",
        "    description=\"Analyze customer survey responses and provide insights\",\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    instructions=\"You have conducted a survey for your service/product and you have collected survey responses for it. Your goal is to analyze those responses and give a concise summary with key points.\",\n",
        "    tools=[\n",
        "        {\n",
        "            \"type\": \"code_interpreter\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "assistant_id = assistant_response.id"
      ],
      "metadata": {
        "id": "nv_se4c3Bu9Z"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assistant_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWyvhYiFR-VL",
        "outputId": "0c385e1c-e687-495c-ca48-de8b87ae8844"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Assistant(id='asst_9YQ8eYduLTsuqdAg1JASiO4Z', created_at=1718276838, description='Analyze customer survey responses and provide insights', instructions='You have conducted a survey for your service/product and you have collected survey responses for it. Your goal is to analyze those responses and give a concise summary with key points.', metadata={}, model='gpt-3.5-turbo', name='Survey Summarizer', object='assistant', tools=[CodeInterpreterTool(type='code_interpreter')], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=ToolResourcesCodeInterpreter(file_ids=[]), file_search=None), top_p=1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"\"\"\n",
        "Give a concise summary from the given customer responses talking about what the customers liked, disliked and what can the organisation do to imporve.\n",
        "Return Format :\n",
        "Summary : (5-6 lines giving general overview)\n",
        "What customers liked : in 2-3 lines\n",
        "What customers disliked : in 2-3 lines\n",
        "What can you imporve : Suggestions for improvement from your side based of responses.\n",
        "Don't return anything else.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ZEcU3z3aBygJ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# thread = client.beta.threads.create(\n",
        "#   messages=[\n",
        "#     {\n",
        "#       \"role\": \"user\",\n",
        "#       \"content\": prompt,\n",
        "#       \"attachments\": [\n",
        "#         {\n",
        "#           \"file_id\": file.id,\n",
        "#           \"tools\": [{\"type\": \"code_interpreter\"}]\n",
        "#         }\n",
        "#       ]\n",
        "#     }\n",
        "#   ]\n",
        "# )\n",
        "message_thread = client.beta.threads.create(\n",
        "    messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": prompt,\n",
        "      \"attachments\": [\n",
        "        {\n",
        "          \"file_id\": file_id,\n",
        "          \"tools\": [{\"type\": \"code_interpreter\"}]\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "\n",
        ")\n",
        "message_thread\n",
        "thread_id=message_thread.id"
      ],
      "metadata": {
        "id": "niQ6eMgLB5HS"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run = client.beta.threads.runs.create_and_poll(\n",
        "  thread_id=thread_id,\n",
        "  assistant_id=assistant_id,\n",
        "  model=\"gpt-4o\"\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "gjcQ1MkWB9LD"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if run.status == 'completed':\n",
        "  messages = client.beta.threads.messages.list(\n",
        "    thread_id=thread_id\n",
        "  )\n",
        "  print(messages)\n",
        "else:\n",
        "  print(run.status)\n",
        "print(\"    \")\n",
        "print(\"gap1\")\n",
        "print(\"    \")\n",
        "\n",
        "messages=client.beta.threads.messages.list(\n",
        "    thread_id=thread_id\n",
        ")\n",
        "print(messages)"
      ],
      "metadata": {
        "id": "knSCqhV0CAAt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f898972-96a7-4e89-a2bc-b4c71b2f8645"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SyncCursorPage[Message](data=[Message(id='msg_OLoMGOJUmeNaFHMxJWf2cWjV', assistant_id='asst_9YQ8eYduLTsuqdAg1JASiO4Z', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Summary: Customers generally found the service ranging from satisfactory to fantastic, with varying opinions on specific aspects such as tracking updates and delivery times. There is a mix of delight and dissatisfaction, indicating room for improvement to elevate customer experiences universally.\\n\\nWhat customers liked: Many customers praised the service, with words like \"fantastic,\" \"impressive,\" and \"exceeded my expectations.\" Some highlighted it as the best logistics service they have used.\\n\\nWhat customers disliked: A notable number of customers mentioned issues related to delays in delivery and inadequate tracking updates. Some also expressed frustration over having to follow up multiple times.\\n\\nWhat can you improve: Enhance the tracking system to provide more accurate and timely updates. Focus on reducing delivery delays and improving communication to minimize the need for customer follow-ups. Streamlining internal processes to address these areas might significantly improve overall satisfaction.'), type='text')], created_at=1718278869, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_2FvSGRDucncvamhh7WWDejob', status=None, thread_id='thread_QglxEw63VHU6cTviC624C8Ug'), Message(id='msg_KLYW2U15nNPXlaeGItbaxWcf', assistant_id=None, attachments=[Attachment(file_id='file-PqYWF09Lqy2qLOpQt7nVO3yw', tools=[CodeInterpreterTool(type='code_interpreter')])], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value=\"\\nGive a concise summary from the given customer responses talking about what the customers liked, disliked and what can the organisation do to imporve.\\nReturn Format :\\nSummary : (5-6 lines giving general overview)\\nWhat customers liked : in 2-3 lines\\nWhat customers disliked : in 2-3 lines\\nWhat can you imporve : Suggestions for improvement from your side based of responses.\\nDon't return anything else.\\n\"), type='text')], created_at=1718278825, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_QglxEw63VHU6cTviC624C8Ug')], object='list', first_id='msg_OLoMGOJUmeNaFHMxJWf2cWjV', last_id='msg_KLYW2U15nNPXlaeGItbaxWcf', has_more=False)\n",
            "    \n",
            "gap1\n",
            "    \n",
            "SyncCursorPage[Message](data=[Message(id='msg_OLoMGOJUmeNaFHMxJWf2cWjV', assistant_id='asst_9YQ8eYduLTsuqdAg1JASiO4Z', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Summary: Customers generally found the service ranging from satisfactory to fantastic, with varying opinions on specific aspects such as tracking updates and delivery times. There is a mix of delight and dissatisfaction, indicating room for improvement to elevate customer experiences universally.\\n\\nWhat customers liked: Many customers praised the service, with words like \"fantastic,\" \"impressive,\" and \"exceeded my expectations.\" Some highlighted it as the best logistics service they have used.\\n\\nWhat customers disliked: A notable number of customers mentioned issues related to delays in delivery and inadequate tracking updates. Some also expressed frustration over having to follow up multiple times.\\n\\nWhat can you improve: Enhance the tracking system to provide more accurate and timely updates. Focus on reducing delivery delays and improving communication to minimize the need for customer follow-ups. Streamlining internal processes to address these areas might significantly improve overall satisfaction.'), type='text')], created_at=1718278869, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_2FvSGRDucncvamhh7WWDejob', status=None, thread_id='thread_QglxEw63VHU6cTviC624C8Ug'), Message(id='msg_KLYW2U15nNPXlaeGItbaxWcf', assistant_id=None, attachments=[Attachment(file_id='file-PqYWF09Lqy2qLOpQt7nVO3yw', tools=[CodeInterpreterTool(type='code_interpreter')])], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value=\"\\nGive a concise summary from the given customer responses talking about what the customers liked, disliked and what can the organisation do to imporve.\\nReturn Format :\\nSummary : (5-6 lines giving general overview)\\nWhat customers liked : in 2-3 lines\\nWhat customers disliked : in 2-3 lines\\nWhat can you imporve : Suggestions for improvement from your side based of responses.\\nDon't return anything else.\\n\"), type='text')], created_at=1718278825, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_QglxEw63VHU6cTviC624C8Ug')], object='list', first_id='msg_OLoMGOJUmeNaFHMxJWf2cWjV', last_id='msg_KLYW2U15nNPXlaeGItbaxWcf', has_more=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a8yLs0DXVuka"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}